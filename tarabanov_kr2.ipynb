{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки и присваиваем им сокращенные названия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_csv('kr2.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем файл с данными используя библиотеку пандас."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>CREA</th>\n",
       "      <th>GGT</th>\n",
       "      <th>PROT</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>38.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>3.23</td>\n",
       "      <td>106.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>38.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>4.80</td>\n",
       "      <td>74.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>46.9</td>\n",
       "      <td>36.2</td>\n",
       "      <td>52.6</td>\n",
       "      <td>5.20</td>\n",
       "      <td>86.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>79.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>43.2</td>\n",
       "      <td>30.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>4.74</td>\n",
       "      <td>80.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>39.2</td>\n",
       "      <td>32.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>4.32</td>\n",
       "      <td>76.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>68.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>62</td>\n",
       "      <td>f</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>110.3</td>\n",
       "      <td>6.30</td>\n",
       "      <td>55.7</td>\n",
       "      <td>650.9</td>\n",
       "      <td>68.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>64</td>\n",
       "      <td>f</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>44.4</td>\n",
       "      <td>3.02</td>\n",
       "      <td>63.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>71.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>64</td>\n",
       "      <td>f</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>66.7</td>\n",
       "      <td>64.2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>46</td>\n",
       "      <td>f</td>\n",
       "      <td>33.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>59</td>\n",
       "      <td>f</td>\n",
       "      <td>36.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.30</td>\n",
       "      <td>67.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Sex   ALB    ALT    AST  CHOL   CREA    GGT  PROT  Category\n",
       "0     32   m  38.5    7.7   22.1  3.23  106.0   12.1  69.0         0\n",
       "1     32   m  38.5   18.0   24.7  4.80   74.0   15.6  76.5         0\n",
       "2     32   m  46.9   36.2   52.6  5.20   86.0   33.2  79.3         0\n",
       "3     32   m  43.2   30.6   22.6  4.74   80.0   33.8  75.7         0\n",
       "4     32   m  39.2   32.6   24.8  4.32   76.0   29.9  68.7         0\n",
       "..   ...  ..   ...    ...    ...   ...    ...    ...   ...       ...\n",
       "610   62   f  32.0    5.9  110.3  6.30   55.7  650.9  68.5         1\n",
       "611   64   f  24.0    2.9   44.4  3.02   63.0   35.9  71.3         1\n",
       "612   64   f  29.0    3.5   99.0  3.63   66.7   64.2  82.0         1\n",
       "613   46   f  33.0   39.0   62.0  4.20   52.0   50.0  71.0         1\n",
       "614   59   f  36.0  100.0   80.0  5.30   67.0   34.0  68.0         1\n",
       "\n",
       "[615 rows x 10 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим датасет на экран. Количество наблюдений 615, количество факторов из них 8 количественные и 1 качественный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHOL</th>\n",
       "      <td>10</td>\n",
       "      <td>0.016260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROT</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALT</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALB</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREA</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AST</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total   Percent\n",
       "CHOL         10  0.016260\n",
       "PROT          1  0.001626\n",
       "ALT           1  0.001626\n",
       "ALB           1  0.001626\n",
       "Category      0  0.000000\n",
       "GGT           0  0.000000\n",
       "CREA          0  0.000000\n",
       "AST           0  0.000000\n",
       "Sex           0  0.000000\n",
       "Age           0  0.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheking Missing data\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем наличие пропусков, присутствуют они только в числовых значениях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Missing data (numeric)\n",
    "def fill_missing_num(x):\n",
    "    num_var = list(x._get_numeric_data().columns)\n",
    "    for col_names in num_var:        \n",
    "        prep_med = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        prep_med.fit(x[num_var])\n",
    "        x[num_var] = prep_med.transform(x[num_var])\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Избавляемся от пропусков, заполняя их средними значениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NA \n",
    "from sklearn.impute import SimpleImputer\n",
    "df = fill_missing_num(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREA</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHOL</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AST</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALB</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total  Percent\n",
       "Category      0      0.0\n",
       "PROT          0      0.0\n",
       "GGT           0      0.0\n",
       "CREA          0      0.0\n",
       "CHOL          0      0.0\n",
       "AST           0      0.0\n",
       "ALT           0      0.0\n",
       "ALB           0      0.0\n",
       "Sex           0      0.0\n",
       "Age           0      0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheking Missing data\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем конечную проверку на наличие пропусков и убеждаемся, что их нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Encoding\n",
    "def encoding_char(x):\n",
    "    char_var = list(set(x.columns) - set(x._get_numeric_data().columns))\n",
    "    for col_names in char_var:\n",
    "        f = pd.factorize(x[col_names])\n",
    "        x[col_names] = pd.factorize(x[col_names])[0]\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодируем качественные переменные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "df = encoding_char(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные результаты запишем в исходный датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>CREA</th>\n",
       "      <th>GGT</th>\n",
       "      <th>PROT</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>3.23</td>\n",
       "      <td>106.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>4.80</td>\n",
       "      <td>74.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.9</td>\n",
       "      <td>36.2</td>\n",
       "      <td>52.6</td>\n",
       "      <td>5.20</td>\n",
       "      <td>86.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>79.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>30.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>4.74</td>\n",
       "      <td>80.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.2</td>\n",
       "      <td>32.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>4.32</td>\n",
       "      <td>76.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>68.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>110.3</td>\n",
       "      <td>6.30</td>\n",
       "      <td>55.7</td>\n",
       "      <td>650.9</td>\n",
       "      <td>68.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>44.4</td>\n",
       "      <td>3.02</td>\n",
       "      <td>63.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>71.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>66.7</td>\n",
       "      <td>64.2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.30</td>\n",
       "      <td>67.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Sex   ALB    ALT    AST  CHOL   CREA    GGT  PROT  Category\n",
       "0    32.0    0  38.5    7.7   22.1  3.23  106.0   12.1  69.0       0.0\n",
       "1    32.0    0  38.5   18.0   24.7  4.80   74.0   15.6  76.5       0.0\n",
       "2    32.0    0  46.9   36.2   52.6  5.20   86.0   33.2  79.3       0.0\n",
       "3    32.0    0  43.2   30.6   22.6  4.74   80.0   33.8  75.7       0.0\n",
       "4    32.0    0  39.2   32.6   24.8  4.32   76.0   29.9  68.7       0.0\n",
       "..    ...  ...   ...    ...    ...   ...    ...    ...   ...       ...\n",
       "610  62.0    1  32.0    5.9  110.3  6.30   55.7  650.9  68.5       1.0\n",
       "611  64.0    1  24.0    2.9   44.4  3.02   63.0   35.9  71.3       1.0\n",
       "612  64.0    1  29.0    3.5   99.0  3.63   66.7   64.2  82.0       1.0\n",
       "613  46.0    1  33.0   39.0   62.0  4.20   52.0   50.0  71.0       1.0\n",
       "614  59.0    1  36.0  100.0   80.0  5.30   67.0   34.0  68.0       1.0\n",
       "\n",
       "[615 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как выглядит таблица после кодирования, можем видеть, что теперь все переменные являются числовыми и можно с ними работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.302757\n",
      "         Iterations 8\n",
      "                         Results: Logit\n",
      "=================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.239     \n",
      "Dependent Variable: y                AIC:              315.9126  \n",
      "Date:               2020-11-23 12:53 BIC:              353.6989  \n",
      "No. Observations:   492              Log-Likelihood:   -148.96   \n",
      "Df Model:           8                LL-Null:          -195.80   \n",
      "Df Residuals:       483              LLR p-value:      8.2841e-17\n",
      "Converged:          1.0000           Scale:            1.0000    \n",
      "No. Iterations:     8.0000                                       \n",
      "--------------------------------------------------------------------\n",
      "       Coef.     Std.Err.       z       P>|z|      [0.025     0.975]\n",
      "--------------------------------------------------------------------\n",
      "x1    -0.0761      0.1593    -0.4779    0.6327    -0.3883     0.2361\n",
      "x2     0.1623      0.1663     0.9761    0.3290    -0.1636     0.4882\n",
      "x3    -0.4483      0.2312    -1.9392    0.0525    -0.9015     0.0048\n",
      "x4    -1.6844      0.2334    -7.2169    0.0000    -2.1418    -1.2269\n",
      "x5     7.0071      0.6382    10.9794    0.0000     5.7563     8.2580\n",
      "x6    -0.4490      0.1805    -2.4876    0.0129    -0.8028    -0.0952\n",
      "x7    -0.0431      0.2424    -0.1776    0.8590    -0.5182     0.4320\n",
      "x8     1.3325      0.3383     3.9393    0.0001     0.6695     1.9954\n",
      "x9     0.2164      0.2058     1.0515    0.2930    -0.1869     0.6197\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline model\n",
    "import statsmodels.api as sm\n",
    "lr = sm.Logit(y_train, X_train).fit()\n",
    "print(lr.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим наш датасет на обучающую и тестовую выборки в пропорции 20% / 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler().fit(X_train)\n",
    "X_train = sc_X.transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем шкалирование данных с помощью библиотеки sklearn.preprocessing, также стоит обратить внимание, что наша эндогенная переменная в шкалировании не нуждается, она уже должна быть дискретного типа (0;1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.302757\n",
      "         Iterations 8\n",
      "                         Results: Logit\n",
      "=================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.239     \n",
      "Dependent Variable: y                AIC:              315.9126  \n",
      "Date:               2020-11-23 14:01 BIC:              353.6989  \n",
      "No. Observations:   492              Log-Likelihood:   -148.96   \n",
      "Df Model:           8                LL-Null:          -195.80   \n",
      "Df Residuals:       483              LLR p-value:      8.2841e-17\n",
      "Converged:          1.0000           Scale:            1.0000    \n",
      "No. Iterations:     8.0000                                       \n",
      "--------------------------------------------------------------------\n",
      "       Coef.     Std.Err.       z       P>|z|      [0.025     0.975]\n",
      "--------------------------------------------------------------------\n",
      "x1    -0.0761      0.1593    -0.4779    0.6327    -0.3883     0.2361\n",
      "x2     0.1623      0.1663     0.9761    0.3290    -0.1636     0.4882\n",
      "x3    -0.4483      0.2312    -1.9392    0.0525    -0.9015     0.0048\n",
      "x4    -1.6844      0.2334    -7.2169    0.0000    -2.1418    -1.2269\n",
      "x5     7.0071      0.6382    10.9794    0.0000     5.7563     8.2580\n",
      "x6    -0.4490      0.1805    -2.4876    0.0129    -0.8028    -0.0952\n",
      "x7    -0.0431      0.2424    -0.1776    0.8590    -0.5182     0.4320\n",
      "x8     1.3325      0.3383     3.9393    0.0001     0.6695     1.9954\n",
      "x9     0.2164      0.2058     1.0515    0.2930    -0.1869     0.6197\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline model\n",
    "import statsmodels.api as sm\n",
    "lr = sm.Logit(y_train, X_train).fit()\n",
    "print(lr.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим базовую модель и посмотрим отчет по этой модели. Можем видеть, что 5 переменных значимые, p-value по остальным переменным превышает 1,29% и я не буду использовать для построения классификаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value < 1,29% Features\n",
    "X_train = X_train[:,[0, 3, 4, 5, 7]]\n",
    "X_test = X_test[:,[0, 3, 4, 5, 7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем тестовую и обучающие выборки, оставив в нех только значимые переменные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression to the Training set (2 variables)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state = 13).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9349593495934959"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = lr.predict(X_test)\n",
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем качество модели, видим что уровень качества очень высокий, то есть больше 93% объектов распознаны верно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107   1]\n",
      " [  7   8]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим таблицу сопряженности, видим, что 7 положительных случая ложно определены как отрицательный, в тоже время 1 негативный исход, определен моделью, как позитивный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "obj = {'X_train': X_train, 'X_test': X_test,'y_train': y_train,'y_test': y_test}\n",
    "output = open('data.pkl', 'wb')\n",
    "pickle.dump(obj, output, 2)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем и поместим в файл data.pkl наши тестовую и обучающую выборки, для дальнейщего использования при построении остальных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "input = open('data.pkl', 'rb')\n",
    "obj = pickle.load(input)\n",
    "input.close()\n",
    "X_train = obj[\"X_train\"]\n",
    "X_test = obj[\"X_test\"]\n",
    "y_train = obj[\"y_train\"]\n",
    "y_test = obj[\"y_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем наши данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки и что важно обновляем их через командую строку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "cnn = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "cnn.add(Dense(units = 10,  activation = 'relu', input_dim = 5))\n",
    "\n",
    "# Adding the output layer\n",
    "cnn.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим нейронную сеть прямой передачи сигнала. Так как параметров для классификации было выбрано 5, соответственно на входном слое находится 5 нейронов. На втором слое выберем 1 нейрон."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.7886 - val_loss: 0.5750 - val_accuracy: 0.8699\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5944 - accuracy: 0.8638 - val_loss: 0.5195 - val_accuracy: 0.8780\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 855us/step - loss: 0.5275 - accuracy: 0.8638 - val_loss: 0.4723 - val_accuracy: 0.8780\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.8638 - val_loss: 0.4333 - val_accuracy: 0.8780\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 881us/step - loss: 0.4281 - accuracy: 0.8638 - val_loss: 0.4008 - val_accuracy: 0.8780\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.3890 - accuracy: 0.8659 - val_loss: 0.3741 - val_accuracy: 0.8862\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8760 - val_loss: 0.3524 - val_accuracy: 0.8943\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8821 - val_loss: 0.3327 - val_accuracy: 0.8943\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.3090 - accuracy: 0.8902 - val_loss: 0.3154 - val_accuracy: 0.8943\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.2898 - accuracy: 0.8984 - val_loss: 0.3004 - val_accuracy: 0.9024\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.2731 - accuracy: 0.9045 - val_loss: 0.2868 - val_accuracy: 0.9106\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 918us/step - loss: 0.2580 - accuracy: 0.9085 - val_loss: 0.2747 - val_accuracy: 0.9106\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 906us/step - loss: 0.2456 - accuracy: 0.9106 - val_loss: 0.2642 - val_accuracy: 0.9187\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 937us/step - loss: 0.2341 - accuracy: 0.9187 - val_loss: 0.2544 - val_accuracy: 0.9187\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 909us/step - loss: 0.2244 - accuracy: 0.9289 - val_loss: 0.2458 - val_accuracy: 0.9268\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 905us/step - loss: 0.2154 - accuracy: 0.9309 - val_loss: 0.2378 - val_accuracy: 0.9268\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 921us/step - loss: 0.2073 - accuracy: 0.9390 - val_loss: 0.2304 - val_accuracy: 0.9268\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.9411 - val_loss: 0.2231 - val_accuracy: 0.9268\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9431 - val_loss: 0.2170 - val_accuracy: 0.9350\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.9472 - val_loss: 0.2114 - val_accuracy: 0.9350\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 905us/step - loss: 0.1812 - accuracy: 0.9492 - val_loss: 0.2058 - val_accuracy: 0.9431\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 918us/step - loss: 0.1757 - accuracy: 0.9472 - val_loss: 0.2005 - val_accuracy: 0.9431\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 876us/step - loss: 0.1710 - accuracy: 0.9472 - val_loss: 0.1960 - val_accuracy: 0.9431\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1671 - accuracy: 0.9492 - val_loss: 0.1916 - val_accuracy: 0.9431\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1630 - accuracy: 0.9492 - val_loss: 0.1882 - val_accuracy: 0.9512\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1593 - accuracy: 0.9533 - val_loss: 0.1846 - val_accuracy: 0.9512\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1558 - accuracy: 0.9512 - val_loss: 0.1811 - val_accuracy: 0.9512\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9512 - val_loss: 0.1784 - val_accuracy: 0.9512\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9512 - val_loss: 0.1752 - val_accuracy: 0.9512\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.9512 - val_loss: 0.1727 - val_accuracy: 0.9512\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1455 - accuracy: 0.9533 - val_loss: 0.1703 - val_accuracy: 0.9512\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1433 - accuracy: 0.9533 - val_loss: 0.1676 - val_accuracy: 0.9512\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9533 - val_loss: 0.1654 - val_accuracy: 0.9512\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1389 - accuracy: 0.9533 - val_loss: 0.1629 - val_accuracy: 0.9512\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.9533 - val_loss: 0.1609 - val_accuracy: 0.9593\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.9533 - val_loss: 0.1590 - val_accuracy: 0.9593\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 900us/step - loss: 0.1337 - accuracy: 0.9553 - val_loss: 0.1573 - val_accuracy: 0.9512\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 854us/step - loss: 0.1323 - accuracy: 0.9553 - val_loss: 0.1559 - val_accuracy: 0.9512\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 818us/step - loss: 0.1307 - accuracy: 0.9573 - val_loss: 0.1541 - val_accuracy: 0.9593\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 780us/step - loss: 0.1292 - accuracy: 0.9593 - val_loss: 0.1524 - val_accuracy: 0.9675\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 830us/step - loss: 0.1275 - accuracy: 0.9593 - val_loss: 0.1515 - val_accuracy: 0.9593\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 794us/step - loss: 0.1264 - accuracy: 0.9593 - val_loss: 0.1504 - val_accuracy: 0.9512\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 833us/step - loss: 0.1249 - accuracy: 0.9614 - val_loss: 0.1494 - val_accuracy: 0.9593\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 789us/step - loss: 0.1236 - accuracy: 0.9614 - val_loss: 0.1480 - val_accuracy: 0.9593\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 849us/step - loss: 0.1226 - accuracy: 0.9634 - val_loss: 0.1474 - val_accuracy: 0.9593\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 818us/step - loss: 0.1215 - accuracy: 0.9654 - val_loss: 0.1456 - val_accuracy: 0.9593\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 809us/step - loss: 0.1204 - accuracy: 0.9654 - val_loss: 0.1446 - val_accuracy: 0.9593\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 836us/step - loss: 0.1191 - accuracy: 0.9654 - val_loss: 0.1434 - val_accuracy: 0.9593\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 884us/step - loss: 0.1180 - accuracy: 0.9654 - val_loss: 0.1423 - val_accuracy: 0.9593\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 992us/step - loss: 0.1169 - accuracy: 0.9654 - val_loss: 0.1409 - val_accuracy: 0.9593\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.9634 - val_loss: 0.1401 - val_accuracy: 0.9593\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.9634 - val_loss: 0.1391 - val_accuracy: 0.9593\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.9634 - val_loss: 0.1374 - val_accuracy: 0.9593\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.9634 - val_loss: 0.1364 - val_accuracy: 0.9593\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.9634 - val_loss: 0.1355 - val_accuracy: 0.9593\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 962us/step - loss: 0.1121 - accuracy: 0.9634 - val_loss: 0.1345 - val_accuracy: 0.9593\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.9634 - val_loss: 0.1339 - val_accuracy: 0.9593\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9654 - val_loss: 0.1329 - val_accuracy: 0.9593\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9654 - val_loss: 0.1322 - val_accuracy: 0.9593\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9675 - val_loss: 0.1316 - val_accuracy: 0.9593\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9675 - val_loss: 0.1313 - val_accuracy: 0.9593\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.9675 - val_loss: 0.1310 - val_accuracy: 0.9593\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9675 - val_loss: 0.1303 - val_accuracy: 0.9593\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 932us/step - loss: 0.1072 - accuracy: 0.9675 - val_loss: 0.1292 - val_accuracy: 0.9593\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 897us/step - loss: 0.1068 - accuracy: 0.9675 - val_loss: 0.1286 - val_accuracy: 0.9593\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 854us/step - loss: 0.1063 - accuracy: 0.9675 - val_loss: 0.1283 - val_accuracy: 0.9593\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 797us/step - loss: 0.1058 - accuracy: 0.9675 - val_loss: 0.1271 - val_accuracy: 0.9593\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 848us/step - loss: 0.1051 - accuracy: 0.9675 - val_loss: 0.1264 - val_accuracy: 0.9593\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 908us/step - loss: 0.1049 - accuracy: 0.9675 - val_loss: 0.1268 - val_accuracy: 0.9593\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 781us/step - loss: 0.1043 - accuracy: 0.9675 - val_loss: 0.1255 - val_accuracy: 0.9593\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 869us/step - loss: 0.1036 - accuracy: 0.9675 - val_loss: 0.1251 - val_accuracy: 0.9593\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 905us/step - loss: 0.1032 - accuracy: 0.9675 - val_loss: 0.1249 - val_accuracy: 0.9593\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 808us/step - loss: 0.1029 - accuracy: 0.9675 - val_loss: 0.1245 - val_accuracy: 0.9593\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 804us/step - loss: 0.1028 - accuracy: 0.9654 - val_loss: 0.1229 - val_accuracy: 0.9675\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 856us/step - loss: 0.1022 - accuracy: 0.9654 - val_loss: 0.1227 - val_accuracy: 0.9675\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 829us/step - loss: 0.1016 - accuracy: 0.9675 - val_loss: 0.1230 - val_accuracy: 0.9675\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 794us/step - loss: 0.1011 - accuracy: 0.9654 - val_loss: 0.1223 - val_accuracy: 0.9675\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 818us/step - loss: 0.1007 - accuracy: 0.9654 - val_loss: 0.1219 - val_accuracy: 0.9675\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 816us/step - loss: 0.1005 - accuracy: 0.9654 - val_loss: 0.1213 - val_accuracy: 0.9675\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 835us/step - loss: 0.1002 - accuracy: 0.9654 - val_loss: 0.1213 - val_accuracy: 0.9675\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.0996 - accuracy: 0.9654 - val_loss: 0.1199 - val_accuracy: 0.9675\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 862us/step - loss: 0.0993 - accuracy: 0.9654 - val_loss: 0.1203 - val_accuracy: 0.9675\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 845us/step - loss: 0.0992 - accuracy: 0.9675 - val_loss: 0.1200 - val_accuracy: 0.9675\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 786us/step - loss: 0.0987 - accuracy: 0.9675 - val_loss: 0.1198 - val_accuracy: 0.9675\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 871us/step - loss: 0.0982 - accuracy: 0.9654 - val_loss: 0.1201 - val_accuracy: 0.9675\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 830us/step - loss: 0.0981 - accuracy: 0.9654 - val_loss: 0.1199 - val_accuracy: 0.9675\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 791us/step - loss: 0.0979 - accuracy: 0.9675 - val_loss: 0.1204 - val_accuracy: 0.9675\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 860us/step - loss: 0.0975 - accuracy: 0.9654 - val_loss: 0.1205 - val_accuracy: 0.9675\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 779us/step - loss: 0.0971 - accuracy: 0.9654 - val_loss: 0.1198 - val_accuracy: 0.9675\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 843us/step - loss: 0.0969 - accuracy: 0.9654 - val_loss: 0.1195 - val_accuracy: 0.9675\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 828us/step - loss: 0.0965 - accuracy: 0.9654 - val_loss: 0.1194 - val_accuracy: 0.9675\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 794us/step - loss: 0.0963 - accuracy: 0.9654 - val_loss: 0.1189 - val_accuracy: 0.9675\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 858us/step - loss: 0.0962 - accuracy: 0.9654 - val_loss: 0.1192 - val_accuracy: 0.9675\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 813us/step - loss: 0.0959 - accuracy: 0.9654 - val_loss: 0.1184 - val_accuracy: 0.9675\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 802us/step - loss: 0.0954 - accuracy: 0.9654 - val_loss: 0.1187 - val_accuracy: 0.9675\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 917us/step - loss: 0.0951 - accuracy: 0.9654 - val_loss: 0.1185 - val_accuracy: 0.9675\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 827us/step - loss: 0.0947 - accuracy: 0.9654 - val_loss: 0.1170 - val_accuracy: 0.9675\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 852us/step - loss: 0.0946 - accuracy: 0.9654 - val_loss: 0.1171 - val_accuracy: 0.9675\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 923us/step - loss: 0.0942 - accuracy: 0.9654 - val_loss: 0.1174 - val_accuracy: 0.9675\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 820us/step - loss: 0.0943 - accuracy: 0.9654 - val_loss: 0.1164 - val_accuracy: 0.9675\n"
     ]
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "history = cnn.fit(X_train, y_train, batch_size = 10, epochs = 100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting loss & accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = cnn.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем прогнозирование, порог оставил прежний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108   0]\n",
      " [  4  11]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построив таблицу сопряженности, видим, что она стала лучше (было 8 неверно распознанных объектов, стало 4). При этом я увеличил количество нейронов на 1ом слое до 10."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
